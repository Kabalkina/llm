{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c217ca45-a5cd-4ba1-94b4-231631646b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee1a1211-a239-4d67-b1c1-6a808b59dcb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - Can I still join the course after the start date?',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50271004-30c2-498b-9f93-742e8d593c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.minsearch.Index at 0x78da3e3b77a0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import minsearch\n",
    "\n",
    "index = minsearch.Index(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")\n",
    "\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1864d52-0b84-410a-adef-170c17535dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "\n",
    "groq_client = Groq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83028c5d-d8e9-4dcd-bcbc-e790c8b6409d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c04ae884-36e0-4d64-9743-593133eea134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: \n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d9f7474-2fcd-4ca7-9a6c-f75504e20fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt):\n",
    "    response = groq_client.chat.completions.create(\n",
    "        model='qwen/qwen3-32b',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8235cd54-ee33-41e8-a32f-a294307e9753",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc32d434-8c81-4cbb-85c1-e4e3da983427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nOkay, the user is asking how to run Kafka. Let me check the provided CONTEXT for relevant information. \\n\\nFirst, looking at the sections related to running Kafka. There\\'s a part about Java Kafka where they mention running producer/consumer using a Java command. The command is java -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java. That\\'s for Java-based Kafka applications.\\n\\nThen there\\'s a Python-related issue where the module “kafka” wasn\\'t found. The solution involves creating a virtual environment, installing requirements from requirements.txt. Commands like python -m venv env, activating the environment, and installing dependencies. Also, notes about Windows paths being different. This would apply if the user is using Python scripts for Kafka.\\n\\nAnother part mentions fixing a Permission denied error on build.sh by using chmod +x build.sh. That\\'s about making the script executable. And there\\'s a ModuleNotFoundError related to \\'kafka.vendor.six.moves\\' suggesting using kafka-python-ng instead of the standard kafka-python package.\\n\\nThe user\\'s question is general, just \"how do I run kafka?\" So I need to outline the steps based on the CONTEXT. The answer should cover both Java and Python scenarios since both are mentioned. For Java, use the Java command with the JAR. For Python, set up a virtual environment, install dependencies. Also mention the chmod command if they encounter permission issues with scripts. Additionally, the kafka-python-ng installation if they face module issues.\\n\\nBut the user might be asking about starting Kafka itself, like the Kafka server. Wait, the CONTEXT doesn\\'t mention starting Kafka server. The FAQs are about running producers/consumers. The user might be in a project where they have their own scripts to run, not the actual Kafka server. The CONTEXT doesn\\'t include steps for starting Zookeeper or Kafka server, so maybe the answer is focused on running their own Kafka producer/consumer apps.\\n\\nSo based on the CONTEXT, the answer should explain for Java and Python. For Java: use the java -cp command with the JAR and class. For Python: setup venv, install requirements. Also mention the build.sh permission fix if needed. Also, note about Docker images being up if that\\'s part of their setup (from the answer mentioning Docker images should be up first).\\n\\nPutting it all together: To run Kafka applications, depending on Java or Python. For Java, use the specified command. For Python, setup venv and install dependencies. Also mention possible fixes like chmod and using kafka-python-ng if needed. Don\\'t include installing dependencies unless necessary, but since another section talks about installing dependencies with pip, maybe mention that if required.\\n\\nSo the structured answer would separate Java and Python steps, including the commands from the CONTEXT, and note about Docker and environment setup.\\n</think>\\n\\nTo run Kafka applications, follow these steps based on your setup:\\n\\n### For Java-based Kafka (Producer/Consumer/KStreams):\\nRun the compiled Java class using the terminal command in your project directory:\\n```bash\\njava -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java\\n```\\nReplace `<jar_name>` with your specific JAR name.\\n\\n---\\n\\n### For Python-based Kafka:\\n1. **Set up a virtual environment** (run once):\\n   ```bash\\n   python -m venv env\\n   source env/bin/activate  # On Windows: env/Scripts/activate\\n   pip install -r ../requirements.txt\\n   ```\\n\\n2. **Activate the virtual environment** before running scripts:\\n   ```bash\\n   source env/bin/activate  # Reactivate as needed\\n   ```\\n\\n3. **Fix permission issues** for scripts like `build.sh`:\\n   ```bash\\n   chmod +x build.sh\\n   ```\\n\\n4. **If encountering a `ModuleNotFoundError`**, use:\\n   ```bash\\n   pip install kafka-python-ng\\n   ```\\n\\n---\\n\\n### Additional Notes:\\n- Ensure Docker images are running for Python workflows (as per the CONTEXT).\\n- If using Python with `requirements.txt`, install dependencies from the virtual environment.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag('how do I run kafka?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86314a2e-dcf8-4c42-bd43-b431293cde47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rag with vector search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "348a0e67-d4a6-4e58-96fe-d79b633c8282",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6be508d7-c71a-425d-8a19-45036ff0bc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "qd_client = QdrantClient(\"http://localhost:6333\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67b3039b-3746-4b9c-ba7d-ed62f1888c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIMENSIONALITY = 512\n",
    "model_handle = \"jinaai/jina-embeddings-v2-small-en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b70f2d76-cc7f-4d20-a445-a70565382cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = \"zoomcamp-faq\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b987fe-548f-45f5-a3c6-53b56d62e068",
   "metadata": {},
   "outputs": [],
   "source": [
    "#qd_client.delete_collection(collection_name=collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbcd2a9f-0dd7-42cb-bb4b-a50ed896f395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qd_client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=EMBEDDING_DIMENSIONALITY,\n",
    "        distance=models.Distance.COSINE\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bec2d3e-b357-4095-80d6-a4a9f3cac397",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = []\n",
    "\n",
    "for i, doc in enumerate(documents):\n",
    "    text = doc['question'] + ' ' + doc['text']\n",
    "    vector = models.Document(text=text, model=model_handle)\n",
    "    point = models.PointStruct(\n",
    "        id=i,\n",
    "        vector=vector,\n",
    "        payload=doc\n",
    "    )\n",
    "    points.append(point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71d5097c-3f99-4490-aa21-737bee67e714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PointStruct(id=0, vector=Document(text=\"Course - When will the course start? The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\", model='jinaai/jina-embeddings-v2-small-en', options=None), payload={'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\", 'section': 'General course-related questions', 'question': 'Course - When will the course start?', 'course': 'data-engineering-zoomcamp'})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25f91fce-4814-42cd-b18d-ce0274e69e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qd_client.upsert(\n",
    "    collection_name=collection_name,\n",
    "    points=points\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4bcfdc32-5b03-45d7-9cd1-7a662e98a6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'I just discovered the course. Can I still join it?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6a5dd53-8d8c-4ab6-8967-c271925216f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_search(question):\n",
    "    print('vector_search is used')\n",
    "    \n",
    "    course = 'data-engineering-zoomcamp'\n",
    "    query_points = qd_client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=models.Document(\n",
    "            text=question,\n",
    "            model=model_handle \n",
    "        ),\n",
    "        query_filter=models.Filter( \n",
    "            must=[\n",
    "                models.FieldCondition(\n",
    "                    key=\"course\",\n",
    "                    match=models.MatchValue(value=course)\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "        limit=5,\n",
    "        with_payload=True\n",
    "    )\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for point in query_points.points:\n",
    "        results.append(point.payload)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0317412e-82a3-4402-bf58-2fd703db72b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = vector_search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8298ecfd-0ee9-4055-a439-0ee7b4afbda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector_search is used\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"<think>\\nOkay, the user is asking how to run Kafka. Let me check the CONTEXT provided.\\n\\nFirst, there's a section on running Java Kafka producers, consumers, etc. The answer mentions using a Java command with the JAR file. Then there are solutions for errors like no brokers available, which relates to Docker setup. Also, there's a Python part about setting up a virtual environment for Kafka in Python.\\n\\nThe user's question is general, but the CONTEXT is split between Java and Python. Since Kafka itself can be run via Docker, maybe they need to start the Docker containers first. The error solutions mention Docker, so that's a key step. \\n\\nThe user might be new and not know the prerequisites. So the answer should probably include starting the Docker setup first using docker-compose. Then, for Java, the specific command to run the producer or consumer. Also, for Python scripts, using a virtual environment as described. \\n\\nI need to make sure the answer covers all necessary steps: Docker setup, Java commands with correct configurations, and Python environment setup if applicable. Also mention checking the server URLs and secrets in the code for Java errors.\\n</think>\\n\\nTo run Kafka, follow these steps based on your setup:\\n\\n1. **Start Kafka via Docker**:  \\n   - Ensure the Kafka broker Docker container is running. Run `docker ps` to confirm. If not, navigate to the Docker Compose YAML file directory and execute:  \\n     ```bash\\n     docker compose up -d\\n     ```\\n\\n2. **Run Java Producer/Consumer**:  \\n   - For Java-based Kafka applications (e.g., `JsonProducer.java` or `JsonConsumer.java`), use the command:  \\n     ```bash\\n     java -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/<ClassName>.java\\n     ```  \\n     Replace `<jar_name>` and `<ClassName>` with your specific values.  \\n   - **Critical**: Verify the `StreamsConfig.BOOTSTRAP_SERVERS_CONFIG` in your Java script uses the correct Kafka server URL (e.g., `europe-west3`) and ensure `Secrets.java` contains valid `KAFKA_CLUSTER_KEY` and `KAFKA_CLUSTER_SECRET`.\\n\\n3. **Python Environment Setup**:  \\n   - For Python scripts (e.g., `producer.py`):  \\n     - Create and activate a virtual environment:  \\n       ```bash\\n       python -m venv env\\n       source env/bin/activate  # Use `env/Scripts/activate` on Windows\\n       pip install -r requirements.txt\\n       ```  \\n     - Run the script within the activated environment.\\n\\n4. **Error Handling**:  \\n   - If encountering `kafka.errors.NoBrokersAvailable`, restart Docker services.  \\n   - If Python scripts fail, ensure you’re using the virtual environment and correct Python executable (e.g., modify scripts to use `python` instead of `python3` on Windows if needed).  \\n\\nAlways ensure your Kafka broker is running before starting producers/consumers.\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag('how do I run kafka?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b797a0b0-f46f-4832-a177-7ef677e543e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
